---
title: "노드 손상"
description: "RustFS 클러스터에서 노드 장애를 처리하는 완전한 단계. 주로 다음을 포함합니다: 대체 노드 하드웨어 준비, 구성 업데이트, 서비스 배포, 클러스터 재참여, 데이터 힐링 및 후속 검사와 모범 사례 등의 핵심 단계."
---

# 노드 손상

분산 RustFS 클러스터에서는 이레이저 코딩(Erasure Coding) 메커니즘을 채택하여 일부 노드 장애 시에도 읽기/쓰기 액세스를 제공하고, 노드가 재참여한 후 자동으로 데이터 힐링을 수행하는 것을 보장합니다. 이 문서는 다음 플로우를 안내합니다:

1. 대체 노드를 시작하고 환경을 동기화
2. DNS/호스트명을 업데이트하여 구 노드 식별자가 신 노드를 가리키도록 함
3. 클러스터와 일치하는 RustFS 서비스를 다운로드 및 배포
4. 신 노드를 클러스터에 재참여시키고 데이터 힐링을 시작
5. 힐링 진행 상황을 모니터링하고 후속 검사 및 최적화 수행

## 1) 대체 노드 시작

* **하드웨어 및 시스템 준비**
  대체 노드의 서버 하드웨어가 장애 노드와 대략 일치하는지 확인합니다. 여기에는 CPU, 메모리, 네트워크 구성 및 디스크 유형이 포함됩니다. 더 높은 사양을 사용해도 클러스터 성능에는 영향을 주지 않습니다.
  소프트웨어 환경은 다른 노드와 버전을 일치시켜야 합니다(운영체제, 커널, 의존성 라이브러리 등). 환경 차이로 인한 클러스터 이상 동작을 방지하기 위함입니다.

* **드라이브 독점 액세스**
  물리 드라이브 작업과 마찬가지로 RustFS는 스토리지 볼륨에 대한 독점 액세스 권한을 요구하며, 다른 프로세스나 스크립트가 스토리지 볼륨 내의 데이터를 직접 수정하는 것을 금지합니다. 그렇지 않으면 데이터 손상이나 중복성 손실을 쉽게 일으킬 수 있습니다.

## 2) 호스트명 및 네트워크 해석 업데이트

* **DNS/Hosts 구성**
  대체 노드의 IP 주소가 장애 노드와 다른 경우, 구 노드의 호스트명(예: `rustfs-node-2.example.net`)을 신 노드로 재해석하여 클러스터 내 각 노드가 동일한 주소를 통해 서로 발견할 수 있도록 해야 합니다.

  ```bash
  # 예시: /etc/hosts에 행을 추가하거나 수정
  192.168.1.12 rustfs-node-2.example.net
  ```

  올바르게 해석된 후 `ping` 또는 `nslookup`으로 호스트명이 신 노드를 가리키는지 확인할 수 있습니다.

## 3) RustFS 서비스 배포 및 구성

* **다운로드 및 설치**
  RustFS 공식의 동일한 버전 배포 플로우에 따라 기존 노드와 일치하는 바이너리 또는 설치 패키지를 다운로드하고 통일된 디렉토리에 압축 해제합니다. 시작 스크립트, 환경 변수 및 구성 파일(`/etc/default/rustfs` 등)이 클러스터 내 다른 노드와 완전히 일치하는지 확인합니다.

* **구성 검증**

  * `config.yaml`의 클러스터 노드 목록(endpoints)에 신 노드의 호스트명과 포트가 포함되어 있는지 확인합니다.
  * 모든 노드의 액세스 키와 권한 구성이 동일한지 확인하여 인증 실패로 인한 신 노드의 참여 불가를 방지합니다.

## 4) 클러스터 재참여 및 데이터 힐링 시작

* **서비스 시작**

  ```bash
  systemctl start rustfs-server
  ```

  또는 사용자 정의 시작 스크립트를 사용하여 RustFS 서비스를 시작하고, `journalctl -u rustfs-server -f`로 시작 로그를 확인하여 신 노드가 다른 온라인 노드를 감지하고 데이터 힐링 프로세스를 시작했는지 확인합니다.

* **힐링 상태 수동 모니터링**
  RustFS 관리 도구(명령을 `rustfs-admin`으로 가정)를 사용하여 클러스터 건강 상태와 힐링 진행 상황을 확인:

  ```bash
  # 클러스터 노드 상태 확인
  rc cluster status

  # 신 노드의 데이터 힐링 시작
  rc heal --node rustfs-node-2.example.net

  # 힐링 진행 상황을 실시간으로 추적
  rc heal status --follow
  ```

  여기서 `heal` 명령은 RustFS의 `rc admin heal`과 유사하며, 모든 손실되거나 일치하지 않는 데이터 조각이 백그라운드에서 복구되는 것을 보장할 수 있습니다.

* **커뮤니티 경험 참고**
  커뮤니티 테스트에 따르면 노드가 오프라인 후 재참여할 때 RustFS는 신 노드에서만 힐링 작업을 수행하고 클러스터 전체를 재균형하지 않아 불필요한 네트워크 및 I/O 피크를 방지합니다.

## 5) 후속 검사 및 모범 사례

* **모니터링 및 알람**

  * 힐링 기간 중 디스크 및 네트워크 부하를 모니터링하여 클러스터가 읽기/쓰기 및 네트워크 대역폭 요구사항을 충족하는지 확인합니다.
  * 노드 힐링이 실패하거나 진행 상황이 임계값을 초과하여 정체될 때 운영 팀에 적시에 알리는 알람을 설정합니다.

* **반복 장애 연습**
  정기적으로 노드 장애를 시뮬레이션하고 전체 복구 플로우를 연습하여 팀이 운영 명령과 응급 단계에 익숙해지도록 보장합니다.

* **근본 원인 분석**
  빈번하게 장애가 발생하는 노드나 디스크에 대해 심도 있는 하드웨어 건강 진단(SMART, BIOS 로그 등)을 수행하고 예방적 유지보수 계획을 채택합니다.

* **전문 지원**
  더 깊이 있는 장애 위치 파악 및 복구 지침이 필요한 경우 RustFS 개발팀이나 커뮤니티에 도움을 요청할 수 있습니다.

---

**요약**: 위의 플로우를 통해 RustFS는 노드 하드웨어에 완전한 장애가 발생한 후 신속하고 안전하게 노드를 교체하고 데이터 힐링을 완료하여 클러스터의 가용성 중단을 최대한 줄일 수 있습니다. 자신의 환경과 구체적인 명령줄 도구에 맞춰 보정하여 구성 일치와 작업 순서의 정확성을 보장하는 것이 중요합니다.

